{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7227d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "import openpifpaf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "from glob import glob\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "from time import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c7f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf80348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenPifPaf version 0.12.14\n",
      "PyTorch version 1.10.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print('OpenPifPaf version', openpifpaf.__version__)\n",
    "print('PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4081da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = glob('datasets/Weizmann/videos/jack/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2280270a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/Weizmann/videos/jack\\\\daria_jack.avi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416f8754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daria_jack'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos[0].split('\\\\')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c58f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir('datasets/Weizmann/frames/jack/daria_jack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a3a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('datasets/Weizmann/frames/walk/davi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "a2b47dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# actions = ['jump', 'pjump', 'run', 'side', 'skip', 'bend', 'wave1', 'wave2']\n",
    "actions = ['wave2']\n",
    "\n",
    "for action in actions:\n",
    "    videos = glob('datasets/Weizmann/videos/'+action+'/*')\n",
    "\n",
    "    for video in tqdm(videos):\n",
    "        name_of_actor = video.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "        if not os.path.isdir('datasets/Weizmann/frames/'+action):\n",
    "            os.mkdir('datasets/Weizmann/frames/'+action)\n",
    "\n",
    "        if not os.path.isdir('datasets/Weizmann/frames/'+action+'/'+name_of_actor):\n",
    "            os.mkdir('datasets/Weizmann/frames/'+action+'/'+name_of_actor)\n",
    "\n",
    "        vidcap = cv2.VideoCapture(video)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            cv2.imwrite(\"datasets/Weizmann/frames/\"+action+\"/\"+name_of_actor+\"/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "            success,image = vidcap.read()\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556f76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folders = glob('datasets/Weizmann/frames/wave2/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a276d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets/Weizmann/frames/wave2\\\\daria_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\denis_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\eli_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\ido_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\ira_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\lena_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\lyova_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\moshe_wave2',\n",
       " 'datasets/Weizmann/frames/wave2\\\\shahar_wave2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eeaeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_actual = glob(frames_folders[0]+\"/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d4f8f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\harbop\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3d9ff75f34436ab707134d21fe915a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for frame_folder in tqdm_notebook(frames_folders):\n",
    "    frames_actual = glob(frame_folder+\"/*.jpg\")\n",
    "    \n",
    "    for frame in frames_actual:\n",
    "        name_of_actor = frame.split('\\\\')[-2]\n",
    "        \n",
    "        if not os.path.isdir('datasets/Weizmann/pifpafheatmaps/wave2'):\n",
    "            os.mkdir('datasets/Weizmann/pifpafheatmaps/wave2')\n",
    "        \n",
    "        if not os.path.isdir('datasets/Weizmann/pifpafheatmaps/wave2/'+name_of_actor):\n",
    "            os.mkdir('datasets/Weizmann/pifpafheatmaps/wave2/'+name_of_actor)\n",
    "        \n",
    "        if not os.path.isdir('datasets/Weizmann/pifpafheatmaps/wave2/'+name_of_actor+'/'+frame.split('\\\\')[-1].split('.')[0]):\n",
    "            os.mkdir('datasets/Weizmann/pifpafheatmaps/wave2/'+name_of_actor+'/'+frame.split('\\\\')[-1].split('.')[0])\n",
    "            \n",
    "        os.system(\n",
    "            \"python -m openpifpaf.predict \"+frame.replace('\\\\', '/')+\" -q --image-output --debug-indices cif:0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16 --save-all=datasets/Weizmann/pifpafheatmaps/wave2/\"+name_of_actor+\"/\"+frame.split('\\\\')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d1c5700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "            \"python -m openpifpaf.predict datasets/Weizmann/pifpafheatmaps/walk/daria_walk/frame0.jpg.predictions.jpeg -q --debug-indices cif:0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16 --save-all=datasets/Weizmann/pifpafheatmaps/walk/\"+name_of_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "9d3badf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_im = PIL.Image.open(\"datasets/Weizmann/frames/wave2/daria_wave2/frame2.jpg\").convert('RGB')\n",
    "im = np.asarray(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "aa150b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k16')\n",
    "predictions, gt_anns, image_meta = predictor.pil_image(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "b0274d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55.26448   ,  57.361076  ,   0.5292886 ],\n",
       "       [ 56.122913  ,  56.136642  ,   0.5642391 ],\n",
       "       [ 54.33905   ,  56.21957   ,   0.45369384],\n",
       "       [ 57.862907  ,  56.669937  ,   0.52911466],\n",
       "       [ 52.918163  ,  56.909115  ,   0.45812553],\n",
       "       [ 60.33988   ,  61.869736  ,   0.7900785 ],\n",
       "       [ 51.33407   ,  62.35469   ,   0.7826369 ],\n",
       "       [ 66.58074   ,  55.598175  ,   0.63352966],\n",
       "       [ 45.442654  ,  57.97446   ,   0.62512916],\n",
       "       [ 67.04378   ,  48.961487  ,   0.56025183],\n",
       "       [ 43.61461   ,  51.079502  ,   0.49001336],\n",
       "       [ 59.138855  ,  79.23557   ,   0.87992495],\n",
       "       [ 53.576714  ,  79.28958   ,   0.8061539 ],\n",
       "       [ 59.25      ,  95.16648   ,   0.8153392 ],\n",
       "       [ 55.661594  ,  94.89848   ,   0.77125716],\n",
       "       [ 59.92888   , 109.05706   ,   0.7682495 ],\n",
       "       [ 57.074055  , 109.06134   ,   0.7292752 ]], dtype=float32)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33b2e388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "            \"python -m openpifpaf.predict datasets/Weizmann/frames/bend/daria_bend/frame25.jpg --json-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "3150b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/Weizmann/frames/bend/daria_bend/frame0.jpg.predictions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "a3cd1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "57a5d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,w,h = data[0]['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "e169fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.8\n",
      "56.15\n",
      "11.34\n",
      "54.65\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(w)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef98071",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x*2\n",
    "y = y*2\n",
    "w = w*2\n",
    "h = h*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "5561daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = (int((x+w/2)), int((y+h/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "d0a3bc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 83)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7670b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"datasets/Weizmann/frames/bend/daria_bend/frame0.jpg.predictions.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "7fd6d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"datasets/Weizmann/frames/bend/daria_bend/frame0.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2572c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_image = img[int(y*2):int(y*2)+int(h*2), int(x*2):int(x*2)+int(w*2)]\n",
    "cropped_image = img[center[1]-40:center[1]+40, center[0]-40:center[0]+40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "bff57835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('contour1.png', cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "314a9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('contour1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "c514b3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=80x80 at 0x1643D881148>"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef258a",
   "metadata": {},
   "source": [
    "### Gerando a média para os heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "b9ee2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob(\"datasets/Weizmann/frames/bend/daria_bend/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "55447bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/Weizmann/frames/bend/daria_bend\\\\frame0.jpg'"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "078ee76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/Weizmann/frames/bend/daria_bend/frame0.jpg.predictions.json')\n",
    "        \n",
    "data = json.load(f)\n",
    "\n",
    "x,y,w,h = data[0]['bbox']\n",
    "\n",
    "center = (int((x+w/2)), int((y+h/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "dcb8bd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 83)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "649cd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs[34:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "91df91f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/Weizmann/frames/bend/daria_bend\\\\frame0.jpg'"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "e4801290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img = cv2.imread(imgs[0])\n",
    "cropped_image = tmp_img[center[1]-80:center[1]+80, center[0]-80:center[0]+80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "81992f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=tmp_img.shape[1], tmp_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "0a80f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob('datasets/Weizmann/frames/bend/daria_bend/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "c9e22915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frame0.jpg'"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].replace('\\\\', '/').split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "212cd25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 153)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "d82ce2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\harbop\\lib\\site-packages\\ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae3618e456b4c859788939c0762fb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = glob('datasets/Weizmann/frames/bend/daria_bend/*.jpg')\n",
    "for image in tqdm_notebook(images):\n",
    "\n",
    "    pil_im = PIL.Image.open(image.replace('\\\\', '/')).convert('RGB')\n",
    "    im = np.asarray(pil_im)\n",
    "\n",
    "\n",
    "    predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k16')\n",
    "    predictions, gt_anns, image_meta = predictor.pil_image(pil_im)\n",
    "\n",
    "    map_colors = {0: np.array([161, 141, 39]),\n",
    "                  5: np.array([193, 10, 80]),\n",
    "                  6: np.array([239, 246, 80]),\n",
    "                  7: np.array([146, 189, 180]),\n",
    "                  8: np.array([234, 213, 170]),\n",
    "                  9: np.array([36, 145, 42]),\n",
    "                  10: np.array([197, 216, 26]),\n",
    "                  11: np.array([218, 70, 117]),\n",
    "                  12: np.array([254, 148, 232]),\n",
    "                  13: np.array([255, 255, 255]),\n",
    "                  14: np.array([255, 0, 0]),\n",
    "                  15: np.array([0, 255, 0]),\n",
    "                  16: np.array([0, 0, 255]),\n",
    "                  }\n",
    "\n",
    "    contour_image = np.zeros((h,w,3),np.float)\n",
    "\n",
    "    for i in np.arange(0,17):\n",
    "        if (predictions[0].data[i][2] != 0) and (i not in [1,2,3,4]):\n",
    "            x = predictions[0].data[i][0]\n",
    "            y = predictions[0].data[i][1]\n",
    "\n",
    "            x = (int(x))+3\n",
    "            y = (int(y))-3\n",
    "\n",
    "            contour_image[int(y)-2:int(y)+2, int(x)-2:int(x)+2] = map_colors[i][::-1]\n",
    "            cropped_image = contour_image[center[1]-40:center[1]+40, center[0]-40:center[0]+40]\n",
    "    \n",
    "    cv2.imwrite('datasets/Weizmann/heatmapsfeatures/bend/daria_bend/'+image.replace('\\\\', '/').split('/')[-1], cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "09eab202",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predictions[0].data[16][0]\n",
    "y = predictions[0].data[16][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "ce9909a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.074055\n",
      "109.06134\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "b7d99298",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (int(x*2))+3\n",
    "y = (int(y*2))-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "1964ac2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "62b2f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_image[int(y)-3:int(y)+3, int(x)-3:int(x)+3] = np.array([0,255,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "99e96ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = contour_image[center[1]-80-30:center[1]+60, center[0]-80:center[0]+80+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "e14e6fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('contour2.png', cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "a262b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('contour2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "1bb75d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKoAAACqCAIAAACyFEPVAAABt0lEQVR4nO3doU4cURQG4N0NCochDZoAKY+AQJCgEChsX4CAaHiKpoKmL4BFragiQVT0ESBAqgnB4JBMFYHeVWxT7t75v8/tyYqT+WfunszunR0MAAAAAAAAAABoyLB2Aw1bPv5YVH4fXlbpZGqj2g1Qk/ijiT+a+KPN1W7gbX5dLRWVjbXbKp30Q2Pxz5Tm5vxJFv9o4o8m/mjiB4AsvvGb0rfzH0XlYGunSif/wugXTfzREm/6nnxdLSqfPl9X6aS6VuO/vzgtKovre1U6aZrFP1qrV391Lc75k1z90cQfLXHxj53zAZ6551/6Ob9bVDYfxxX6eBd9/ux/eNwtKgvz4wp9zDCTfzTxRxN/NPFH6/PoN50ez/kAAAAAAAAAAAAAAAAAwKwIerjL0/e7ojLa//D65c32UfGGlbMv/7en2mzwjib+aOKPJv5o4gcAAAAAAAAAAAAAAIDagjZ4v9ZNVDIPhL9wftF15VkxHPb8rLDHL5r4o4k/mvijhY5+PZ/oAAAAAAAAAAAAAICm+cXzxG7P7u9j0usjZJtHNPFHE3808UcTPwAAAAAAAAAAAAAAAEBFfwA2lSgcF43G+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=170x170 at 0x1643D7ADBC8>"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "b97c00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folders = glob('datasets/Weizmann/frames/bend/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "bb2132a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\harbop\\lib\\site-packages\\ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77206a46b440461fbb27fad0fe1d15ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actions = ['walk']\n",
    "# actions = ['jack', 'bend', 'jump', 'pjump', 'run', 'side', 'skip', 'bend', 'wave1', 'wave2']\n",
    "for action in actions:\n",
    "    frames_folders = glob('datasets/Weizmann/frames/'+action+'/*')\n",
    "    for frame_folder in tqdm_notebook(frames_folders):\n",
    "        frames_actual = glob(frame_folder+\"/*.jpg\")\n",
    "\n",
    "        for frame in frames_actual[2:]:\n",
    "            name_of_actor = frame.split('\\\\')[-2]\n",
    "\n",
    "\n",
    "            tmp_img = cv2.imread(frame)\n",
    "\n",
    "            if not os.path.isdir('datasets/Weizmann/heatmapsfeatures/'+action):\n",
    "                os.mkdir('datasets/Weizmann/heatmapsfeatures/'+action)\n",
    "\n",
    "            if not os.path.isdir('datasets/Weizmann/heatmapsfeatures/'+action+'/'+name_of_actor):\n",
    "                os.mkdir('datasets/Weizmann/heatmapsfeatures/'+action+'/'+name_of_actor)\n",
    "\n",
    "            f = open('datasets/Weizmann/frames/'+action+'/'+name_of_actor+'/'+frame.replace('\\\\', '/').split('/')[-1]+'.predictions.json')\n",
    "\n",
    "            data = json.load(f)\n",
    "\n",
    "            x,y,w,h = data[0]['bbox']\n",
    "\n",
    "            center = (int((x+w/2)), int((y+h/2)))\n",
    "\n",
    "            w,h=tmp_img.shape[1], tmp_img.shape[0]\n",
    "\n",
    "            pil_im = PIL.Image.open(frame.replace('\\\\', '/')).convert('RGB')\n",
    "            im = np.asarray(pil_im)\n",
    "\n",
    "            predictor = openpifpaf.Predictor(checkpoint='shufflenetv2k16')\n",
    "            predictions, gt_anns, image_meta = predictor.pil_image(pil_im)\n",
    "\n",
    "            map_colors = {0: np.array([161, 141, 39]),\n",
    "                          5: np.array([193, 10, 80]),\n",
    "                          6: np.array([239, 246, 80]),\n",
    "                          7: np.array([146, 189, 180]),\n",
    "                          8: np.array([234, 213, 170]),\n",
    "                          9: np.array([36, 145, 42]),\n",
    "                          10: np.array([197, 216, 26]),\n",
    "                          11: np.array([218, 70, 117]),\n",
    "                          12: np.array([254, 148, 232]),\n",
    "                          13: np.array([255, 255, 255]),\n",
    "                          14: np.array([255, 0, 0]),\n",
    "                          15: np.array([0, 255, 0]),\n",
    "                          16: np.array([0, 0, 255]),\n",
    "                          }\n",
    "\n",
    "            contour_image = np.zeros((h,w,3),np.float)\n",
    "\n",
    "            window_x_negative, window_x_positive, window_y_negative, window_y_positive = 50, 50, 50, 50\n",
    "            if center[0]-window_x_negative < 0:\n",
    "                window_x_negative = center[0]\n",
    "                window_x_positive = 50+(50-center[0])\n",
    "            if center[1]-window_y_negative < 0:\n",
    "                window_y_negative = center[1]\n",
    "                window_y_positive = 50+(50-center[1])\n",
    "\n",
    "            if center[0]+window_x_positive > img.shape[1]:\n",
    "                window_x_negative = 50+(50-(img.shape[1]-center[0]))\n",
    "                window_x_positive = (img.shape[1]-center[0])\n",
    "            if center[1]+window_y_positive > img.shape[0]:\n",
    "                window_y_negative = 50+(50-(img.shape[0]-center[1]))\n",
    "                window_y_positive = (img.shape[0]-center[1])\n",
    "\n",
    "            for i in np.arange(0,17):\n",
    "                if (predictions[0].data[i][2] != 0) and (i not in [1,2,3,4]):\n",
    "                    x = predictions[0].data[i][0]\n",
    "                    y = predictions[0].data[i][1]\n",
    "\n",
    "                    x = (int(x))+3\n",
    "                    y = (int(y))-3\n",
    "\n",
    "                    contour_image[int(y)-2:int(y)+2, int(x)-2:int(x)+2] = map_colors[i][::-1]\n",
    "                    cropped_image = contour_image[center[1]-window_y_negative:center[1]+window_y_positive, center[0]-window_x_negative:center[0]+window_x_positive]\n",
    "\n",
    "            cv2.imwrite(\"datasets/Weizmann/heatmapsfeatures/\"+action+\"/\"+name_of_actor+\"/\"+frame.replace('\\\\', '/').split('/')[-1], cropped_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img = cv2.imread(imgs[0])\n",
    "cropped_image = tmp_img[center[1]-80-25:center[1]+60, center[0]-80:center[0]+80+10]\n",
    "arr = np.array(cropped_image)\n",
    "\n",
    "for img in imgs[1:]:\n",
    "    tmp_img = cv2.imread(img)\n",
    "    cropped_image = tmp_img[center[1]-80-25:center[1]+60, center[0]-80:center[0]+80+10]\n",
    "    w,h=Image.open(images[0]).size\n",
    "\n",
    "            imarr=np.array(Image.open(im),dtype=np.float)\n",
    "            arr=arr+imarr/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a3bd4dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "imgs = glob(\"datasets/Weizmann/pifpafheatmaps/bend/daria_bend/frame0/*.jpeg\")\n",
    "imgs = imgs[34:]\n",
    "\n",
    "tmp_img = cv2.imread(imgs[0])\n",
    "cropped_image = tmp_img[center[1]-80-30:center[1]+60, center[0]-80:center[0]+80+10]\n",
    "\n",
    "w,h=cropped_image.shape[0], cropped_image.shape[1]\n",
    "N=len(imgs)\n",
    "print(w)\n",
    "print(h)\n",
    "\n",
    "# Create a numpy array of floats to store the average (assume RGB images)\n",
    "arr=np.zeros((h,w,3),np.float)\n",
    "\n",
    "# Build up average pixel intensities, casting each image as an array of floats\n",
    "for im in imgs:\n",
    "    imarr=np.array(Image.open(im),dtype=np.float)\n",
    "    cropped_image = imarr[center[1]-80-30:center[1]+60, center[0]-80:center[0]+80+10]\n",
    "    arr=arr+cropped_image/N\n",
    "\n",
    "# Round values in array and cast as 8-bit integer\n",
    "arr=np.array(np.round(arr),dtype=np.uint8)\n",
    "out=Image.fromarray(arr,mode=\"RGB\")\n",
    "out.save(\"Average.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02d3998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/Weizmann/frames/jump/daria_jump/frame60.jpg.predictions.json')\n",
    "        \n",
    "data = json.load(f)\n",
    "\n",
    "x,y,w,h = data[0]['bbox']\n",
    "\n",
    "x = x*2\n",
    "y = y*2\n",
    "w = w*2\n",
    "h = h*2\n",
    "\n",
    "center = (int((x+w/2)), int((y+h/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "535d3c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 160)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f673a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"datasets/Weizmann/frames/jump/daria_jump/frame60.jpg.predictions.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82247bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 360, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf50863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_x_negative, window_x_positive, window_y_negative, window_y_positive = 80, 80, 80, 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9e08d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if center[0]-window_x_negative < 0:\n",
    "    window_x_negative = center[0]\n",
    "    window_x_positive = 80+(80-center[0])\n",
    "if center[1]-window_y_negative < 0:\n",
    "    window_y_negative = center[1]\n",
    "    window_y_positive = 80+(80-center[1])\n",
    "\n",
    "if center[0]+window_x_positive > img.shape[1]:\n",
    "    window_x_negative = 80+(80-(img.shape[1]-center[0]))\n",
    "    window_x_positive = (img.shape[1]-center[0])\n",
    "if center[1]+window_y_positive > img.shape[0]:\n",
    "    window_y_negative = 80+(80-(img.shape[0]-center[1]))\n",
    "    window_y_positive = (img.shape[0]-center[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87ca36d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[1]-window_y_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70da6685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[1]+window_y_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "edf32304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[0]-window_x_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "434faae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[0]+window_x_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10a06c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = img[center[1]-window_y_negative:center[1]+window_y_positive, center[0]-window_x_negative:center[0]+window_x_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1287a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[149, 144, 153],\n",
       "        [148, 143, 152],\n",
       "        [149, 142, 149],\n",
       "        ...,\n",
       "        [153, 146, 153],\n",
       "        [154, 147, 154],\n",
       "        [155, 148, 155]],\n",
       "\n",
       "       [[149, 144, 153],\n",
       "        [149, 144, 153],\n",
       "        [151, 144, 151],\n",
       "        ...,\n",
       "        [155, 147, 154],\n",
       "        [155, 148, 155],\n",
       "        [157, 150, 157]],\n",
       "\n",
       "       [[147, 142, 151],\n",
       "        [148, 143, 152],\n",
       "        [150, 143, 150],\n",
       "        ...,\n",
       "        [155, 147, 154],\n",
       "        [156, 149, 156],\n",
       "        [157, 150, 157]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[151, 138, 136],\n",
       "        [149, 137, 135],\n",
       "        [150, 137, 135],\n",
       "        ...,\n",
       "        [154, 137, 140],\n",
       "        [152, 135, 138],\n",
       "        [151, 134, 137]],\n",
       "\n",
       "       [[162, 147, 144],\n",
       "        [160, 145, 142],\n",
       "        [160, 145, 142],\n",
       "        ...,\n",
       "        [150, 129, 131],\n",
       "        [148, 127, 129],\n",
       "        [146, 125, 127]],\n",
       "\n",
       "       [[141, 125, 119],\n",
       "        [140, 124, 118],\n",
       "        [140, 124, 118],\n",
       "        ...,\n",
       "        [111,  90,  92],\n",
       "        [109,  88,  90],\n",
       "        [106,  85,  87]]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a09c565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_actual = glob(frames_folders[0]+\"/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2831d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folders = glob('datasets/Weizmann/frames/walk/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8bcfaadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datasets/Weizmann/frames/walk\\\\daria_walk'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_folders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2e0d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\harbop\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7241cba93f3e4f2082fdc866b446aae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for frame_folder in tqdm_notebook(frames_folders):\n",
    "    frames_actual = glob(frame_folder+\"/*.jpg\")\n",
    "    \n",
    "    for frame in frames_actual:\n",
    "        name_of_actor = frame.split('\\\\')[-2]\n",
    "        \n",
    "        if not os.path.isdir('datasets/Weizmann/skeletons_croppeds/walk'):\n",
    "            os.mkdir('datasets/Weizmann/skeletons_croppeds/walk')\n",
    "        \n",
    "        if not os.path.isdir('datasets/Weizmann/skeletons_croppeds/walk/'+name_of_actor):\n",
    "            os.mkdir('datasets/Weizmann/skeletons_croppeds/walk/'+name_of_actor)\n",
    "        \n",
    "        os.system(\n",
    "            \"python -m openpifpaf.predict \"+frame.replace('\\\\', '/')+\" --json-output\")\n",
    "        \n",
    "        f = open('datasets/Weizmann/frames/walk/'+name_of_actor+'/'+frame.replace('\\\\', '/').split('/')[-1]+'.predictions.json')\n",
    "        \n",
    "        data = json.load(f)\n",
    "        \n",
    "        x,y,w,h = data[0]['bbox']\n",
    "        \n",
    "        x = x*2\n",
    "        y = y*2\n",
    "        w = w*2\n",
    "        h = h*2\n",
    "        \n",
    "        center = (int((x+w/2)), int((y+h/2)))\n",
    "        \n",
    "        img = cv2.imread(\"datasets/Weizmann/frames/walk/\"+name_of_actor+\"/\"+frame.replace('\\\\', '/').split('/')[-1]+\".predictions.jpeg\")\n",
    "        \n",
    "        window_x_negative, window_x_positive, window_y_negative, window_y_positive = 80, 80, 80, 80\n",
    "        if center[0]-window_x_negative < 0:\n",
    "            window_x_negative = center[0]\n",
    "            window_x_positive = 80+(80-center[0])\n",
    "        if center[1]-window_y_negative < 0:\n",
    "            window_y_negative = center[1]\n",
    "            window_y_positive = 80+(80-center[1])\n",
    "\n",
    "        if center[0]+window_x_positive > img.shape[1]:\n",
    "            window_x_negative = 80+(80-(img.shape[1]-center[0]))\n",
    "            window_x_positive = (img.shape[1]-center[0])\n",
    "        if center[1]+window_y_positive > img.shape[0]:\n",
    "            window_y_negative = 80+(80-(img.shape[0]-center[1]))\n",
    "            window_y_positive = (img.shape[0]-center[1])\n",
    "            \n",
    "        cropped_image = img[center[1]-window_y_negative:center[1]+window_y_positive, center[0]-window_x_negative:center[0]+window_x_positive]\n",
    "        \n",
    "        cv2.imwrite(\"datasets/Weizmann/skeletons_croppeds/walk/\"+name_of_actor+\"/\"+frame.replace('\\\\', '/').split('/')[-1], cropped_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad5bb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all PNG files in directory\n",
    "# allfiles=os.listdir(os.getcwd())\n",
    "# imlist=[filename for filename in allfiles if  filename[-4:] in [\".png\",\".PNG\"]]\n",
    "\n",
    "# Assuming all images are the same size, get dimensions of first image\n",
    "w,h=Image.open(images[0]).size\n",
    "N=len(images)\n",
    "\n",
    "# Create a numpy array of floats to store the average (assume RGB images)\n",
    "arr=np.zeros((h,w,3),np.float)\n",
    "\n",
    "# Build up average pixel intensities, casting each image as an array of floats\n",
    "for im in images:\n",
    "    imarr=np.array(Image.open(im),dtype=np.float)\n",
    "    arr=arr+imarr/N\n",
    "\n",
    "# Round values in array and cast as 8-bit integer\n",
    "arr=np.array(np.round(arr),dtype=np.uint8)\n",
    "\n",
    "# Generate, save and preview final image\n",
    "out=Image.fromarray(arr,mode=\"RGB\")\n",
    "out.save(\"Average.png\")\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a011d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Harbop",
   "language": "python",
   "name": "harbop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
